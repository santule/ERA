{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "V8XumFn4EQjp",
        "rfP7zepexo7z"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHNxqHKN6Yti2MzWYz3/nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b964fb5c930c4236a9e9b9c30ee6282f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a69959d4e8704497949d85db8e1be8c3",
              "IPY_MODEL_4bce9a30e6644f12a1f795cf7c005f0f",
              "IPY_MODEL_0f198aa85430416785253892e3e2273e"
            ],
            "layout": "IPY_MODEL_91f019031c7844328dad82839db1c4d2"
          }
        },
        "a69959d4e8704497949d85db8e1be8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571bd0b5672b4809b305c32ab4d75d5f",
            "placeholder": "​",
            "style": "IPY_MODEL_c096b433b8aa4aef80ffa5a129eb8b1d",
            "value": "100%"
          }
        },
        "4bce9a30e6644f12a1f795cf7c005f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c6eca077c4497c94749b7e8964d1d8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27672b77091b4712a4d2f14817650286",
            "value": 2
          }
        },
        "0f198aa85430416785253892e3e2273e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc79984f201494e97b17dbb5a054529",
            "placeholder": "​",
            "style": "IPY_MODEL_606fdc1ded654dffb451d9bdc0949b50",
            "value": " 2/2 [06:42&lt;00:00, 200.01s/it]"
          }
        },
        "91f019031c7844328dad82839db1c4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571bd0b5672b4809b305c32ab4d75d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c096b433b8aa4aef80ffa5a129eb8b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54c6eca077c4497c94749b7e8964d1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27672b77091b4712a4d2f14817650286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bc79984f201494e97b17dbb5a054529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606fdc1ded654dffb451d9bdc0949b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santule/ERA/blob/main/S17/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAPAycLmC-f6",
        "outputId": "20c48935-884b-4773-bd7a-e8fe3b614e1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OVQ7w5JGiw-j"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import transformer\n",
        "import re\n",
        "from os.path import exists\n",
        "from collections import Counter\n",
        "import random\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/AI/ERA_course/session17"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icyhl5X0DDN4",
        "outputId": "85046549-5550-40c8-89ed-ef453e66d029"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/AI/ERA_course/session17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "n_vocab = 40000\n",
        "seq_len = 20\n",
        "p_random_mask = 0.15\n",
        "batch_size = 16\n",
        "n_iterations = 20\n",
        "epochs = 2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "0PDs1JplkMNw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Load data"
      ],
      "metadata": {
        "id": "V8XumFn4EQjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pth = 'sentences_data/training.txt'\n",
        "sentences = open(data_pth).read().lower().split('\\n')\n",
        "special_chars = '?;.:/*!+-()[]{}\"\\'&'\n",
        "sentences = [re.sub(f'[{re.escape(special_chars)}]','\\g<0> ',s).split(' ') for s in sentences]\n",
        "sentences = [[w for w in s if len(w)] for s in sentences]"
      ],
      "metadata": {
        "id": "jWtKGXvFEShj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocab\n",
        "vocab_pth = 'sentences_data/vocab.txt'\n",
        "if not exists(vocab_pth):\n",
        "  words = [w for s in sentences for w in s]\n",
        "  vocab = Counter(words).most_common(n_vocab)\n",
        "  vocab = [w[0] for w in vocab]\n",
        "else:\n",
        "  vocab = open(vocab_pth).read().split('\\n')"
      ],
      "metadata": {
        "id": "jmRDr8cMHeyX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceDataset(Dataset):\n",
        "  def __init__(self,sentences,vocab,seq_len):\n",
        "    dataset = self\n",
        "    dataset.sentences = sentences\n",
        "    dataset.vocab = vocab + ['<ignore>','<oov>','<mask>']\n",
        "    dataset.vocab = {e:i for i,e in enumerate(dataset.vocab)}\n",
        "    dataset.rvocab = {v:k for k,v in dataset.vocab.items()}\n",
        "\n",
        "    dataset.seq_len = seq_len\n",
        "\n",
        "    dataset.IGNORE_IDX = dataset.vocab['<ignore>']\n",
        "    dataset.OUT_OF_VOCAB_IDX = dataset.vocab['<oov>']\n",
        "    dataset.MASK_IDX = dataset.vocab['<mask>']\n",
        "\n",
        "  def __getitem__(self,index,p_random_mask=0.15):\n",
        "    dataset = self\n",
        "\n",
        "    s = []\n",
        "    while len(s) < dataset.seq_len:\n",
        "      s.extend(dataset.get_sentence_idx(index % len(dataset)))\n",
        "      index += 1\n",
        "\n",
        "    s = s[:dataset.seq_len]\n",
        "    [s.append(dataset.IGNORE_IDX) for i in range(dataset.seq_len - len(s))]\n",
        "    s = [(dataset.MASK_IDX,w) if random.random() < p_random_mask else (w,dataset.IGNORE_IDX) for w in s]\n",
        "\n",
        "    return {'input': torch.Tensor([w[0] for w in s]).long(),\n",
        "            'target':torch.Tensor([w[1] for w in s]).long()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "\n",
        "  def get_sentence_idx(self,index):\n",
        "    dataset = self\n",
        "    s = dataset.sentences[index]\n",
        "    s = [dataset.vocab[w] if w in dataset.vocab else dataset.OUT_OF_VOCAB_IDX for w in s]\n",
        "    return s"
      ],
      "metadata": {
        "id": "O-RtBI5-BEhX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset and train/test data\n",
        "print('creating dataset...')\n",
        "dataset = SentenceDataset(sentences, vocab, seq_len)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "print(f\"size of train {train_size} and size of test {test_size}\")\n",
        "\n",
        "#dataloader = torch.utils.data.DataLoader(dataset,shuffle=True, drop_last=True, pin_memory=False, batch_size=batch_size)\n",
        "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,batch_size = batch_size,\n",
        "                              shuffle=True,num_workers=2,\n",
        "                              pin_memory=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,batch_size = batch_size,\n",
        "                              shuffle=False,num_workers=2,\n",
        "                              pin_memory=True)\n",
        "\n",
        "\n",
        "# sample sentence\n",
        "batch_output = next(iter(train_dataloader))\n",
        "input_sentence, input_label = batch_output['input'][0], batch_output['target'][0]\n",
        "print(input_sentence, input_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOJ_WSmqLvB7",
        "outputId": "ab3279d5-52d8-4639-8ae0-2972dc649ae3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating dataset...\n",
            "size of train 99565 and size of test 24892\n",
            "tensor([  866,  2770,    25,  4569,    13, 40002,   175,    30,   112,    20,\n",
            "            2,  2021,   226,    14,     5,   198, 22475,    63, 40002,  6389]) tensor([40000, 40000, 40000, 40000, 40000,     0, 40000, 40000, 40000, 40000,\n",
            "        40000, 40000, 40000, 40000, 40000, 40000, 40000, 40000,    25, 40000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Load model"
      ],
      "metadata": {
        "id": "WF2_wyx0kka0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = transformer.Bert(n_embeddings = len(dataset.vocab))\n",
        "bert_model.to(device)\n",
        "optimizer = torch.optim.Adam(params = bert_model.parameters(),lr=1e-4,betas=(0.9,0.999),\n",
        "                             weight_decay=1e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=dataset.IGNORE_IDX)\n",
        "summary(model= bert_model, input_size=(32,20), dtypes = [torch.int32],col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiT_kPRikvaE",
        "outputId": "90a0123d-da9c-427f-d9ee-1180b5c14358"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "Bert (Bert)                                                  [32, 20]             [32, 20, 40003]      2,560                True\n",
              "├─Embedding (embeddings)                                     [32, 20]             [32, 20, 128]        5,120,384            True\n",
              "├─Dropout (embedding_dropout)                                [32, 20, 128]        [32, 20, 128]        --                   --\n",
              "├─Sequential (transformer_encoder)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    └─TransformerEncoderBlock (0)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (1)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (2)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (3)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (4)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (5)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (6)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "│    └─TransformerEncoderBlock (7)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
              "├─Sequential (output_embedding)                              [32, 20, 128]        [32, 20, 40003]      --                   True\n",
              "│    └─LayerNorm (0)                                         [32, 20, 128]        [32, 20, 128]        256                  True\n",
              "│    └─Linear (1)                                            [32, 20, 128]        [32, 20, 40003]      5,120,384            True\n",
              "============================================================================================================================================\n",
              "Total params: 11,829,760\n",
              "Trainable params: 11,829,760\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 361.56\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 242.83\n",
              "Params size (MB): 45.20\n",
              "Estimated Total Size (MB): 288.02\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Train model (epochs)"
      ],
      "metadata": {
        "id": "tG6hjc_VmRTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "  # train model\n",
        "  bert_model.train()\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch_idx, batch_data in enumerate(train_dataloader):\n",
        "\n",
        "    #infer\n",
        "    masked_input  = batch_data['input']\n",
        "    masked_target = batch_data['target']\n",
        "\n",
        "    masked_input  = masked_input.to(device)\n",
        "    masked_target = masked_target.to(device)\n",
        "    output_pred = bert_model(masked_input)\n",
        "\n",
        "    # compute the cross entropy loss\n",
        "    output_v = output_pred.view(-1,output_pred.shape[-1])\n",
        "    target_v = masked_target.view(-1,1).squeeze()\n",
        "    loss = loss_fn(output_v, target_v)\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss = train_loss / len(train_dataloader)\n",
        "\n",
        "  # test model\n",
        "  bert_model.eval()\n",
        "  test_loss= 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch_idx, batch_data in enumerate(test_dataloader):\n",
        "      #infer\n",
        "      masked_input  = batch_data['input']\n",
        "      masked_target = batch_data['target']\n",
        "\n",
        "      masked_input  = masked_input.to(device)\n",
        "      masked_target = masked_target.to(device)\n",
        "      output_pred = bert_model(masked_input)\n",
        "\n",
        "      #compute the cross entropy loss\n",
        "      output_v = output_pred.view(-1,output_pred.shape[-1])\n",
        "      target_v = masked_target.view(-1,1).squeeze()\n",
        "      loss = loss_fn(output_v, target_v)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "\n",
        "    test_loss = test_loss / len(test_dataloader)\n",
        "\n",
        "\n",
        "  print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "           f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"| Δw:, {round(bert_model.embeddings.weight.grad.abs().sum().item(),3)}\"\n",
        "\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "b964fb5c930c4236a9e9b9c30ee6282f",
            "a69959d4e8704497949d85db8e1be8c3",
            "4bce9a30e6644f12a1f795cf7c005f0f",
            "0f198aa85430416785253892e3e2273e",
            "91f019031c7844328dad82839db1c4d2",
            "571bd0b5672b4809b305c32ab4d75d5f",
            "c096b433b8aa4aef80ffa5a129eb8b1d",
            "54c6eca077c4497c94749b7e8964d1d8",
            "27672b77091b4712a4d2f14817650286",
            "7bc79984f201494e97b17dbb5a054529",
            "606fdc1ded654dffb451d9bdc0949b50"
          ]
        },
        "id": "6ZQulr4tmQmd",
        "outputId": "f1e2c4cd-1a16-412c-a6bf-74747c5ee311"
      },
      "execution_count": 17,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b964fb5c930c4236a9e9b9c30ee6282f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 7.4861 | test_loss: 7.2754 | | Δw:, 4.989\n",
            "Epoch: 2 | train_loss: 7.1771 | test_loss: 7.1053 | | Δw:, 10.734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Train model (iterations)"
      ],
      "metadata": {
        "id": "rfP7zepexo7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(loader,loader_iter):\n",
        "  try:\n",
        "        batch = next(loader_iter)\n",
        "  except StopIteration:\n",
        "      loader_iter = iter(loader)\n",
        "      batch = next(loader_iter)\n",
        "  return batch, loader_iter"
      ],
      "metadata": {
        "id": "JbV6cT0fyyax"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_iter = iter(train_dataloader)\n",
        "bert_model.train()\n",
        "print_each = 10\n",
        "\n",
        "for it in range(n_iterations):\n",
        "  #get batch\n",
        "  batch_data, batch_iter = get_batch(train_dataloader, batch_iter)\n",
        "\n",
        "  masked_input  = batch_data['input']\n",
        "  masked_target = batch_data['target']\n",
        "\n",
        "  masked_input  = masked_input.to(device)\n",
        "  masked_target = masked_target.to(device)\n",
        "  output_pred   = bert_model(masked_input)\n",
        "\n",
        "  #compute the cross entropy loss\n",
        "  output_v = output_pred.view(-1,output_pred.shape[-1])\n",
        "  target_v = masked_target.view(-1,1).squeeze()\n",
        "  loss = loss_fn(output_v, target_v)\n",
        "\n",
        "  train_loss += loss.item()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  #print step\n",
        "  if it % print_each == 0:\n",
        "      print('it:', it,\n",
        "            ' | loss', np.round(loss.item(),2),\n",
        "            ' | Δw:', round(bert_model.embeddings.weight.grad.abs().sum().item(),3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekRHu4JcxqQl",
        "outputId": "de2b908a-80ba-40c2-b681-1b5e578a112d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it: 0  | loss 10.7  | Δw: 4.22\n",
            "it: 10  | loss 10.37  | Δw: 3.279\n"
          ]
        }
      ]
    }
  ]
}