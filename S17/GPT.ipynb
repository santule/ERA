{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yYV-93gK1U9_"
      ],
      "authorship_tag": "ABX9TyN7AHaVa+vef2Na1xlCBJeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fef04649033473cb48c57b8cb39cb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e31c537ca534875a5a44111e6df6709",
              "IPY_MODEL_21371f1313ed4b23ba67f400df4440cf",
              "IPY_MODEL_02048bdae5fa4ec58bf95226b6f76b9e"
            ],
            "layout": "IPY_MODEL_27639e3bd9fb489caa4a251998658e6a"
          }
        },
        "3e31c537ca534875a5a44111e6df6709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10ab641bd496414ca70ddd5275bb48e6",
            "placeholder": "​",
            "style": "IPY_MODEL_3b01f022e5774501b247fc06346fe2a6",
            "value": "100%"
          }
        },
        "21371f1313ed4b23ba67f400df4440cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e5fe7c141b4ccdb78b95c932fddacc",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7659d76c8180441290bd41d7b8987550",
            "value": 20
          }
        },
        "02048bdae5fa4ec58bf95226b6f76b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0ba54573f44616a150b1f97d8d758f",
            "placeholder": "​",
            "style": "IPY_MODEL_ec6e296628c3476ea9c85b09c8579f60",
            "value": " 20/20 [05:26&lt;00:00, 13.03s/it]"
          }
        },
        "27639e3bd9fb489caa4a251998658e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ab641bd496414ca70ddd5275bb48e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b01f022e5774501b247fc06346fe2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0e5fe7c141b4ccdb78b95c932fddacc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7659d76c8180441290bd41d7b8987550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b0ba54573f44616a150b1f97d8d758f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6e296628c3476ea9c85b09c8579f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santule/ERA/blob/main/S17/GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "01ydyCg10ms_"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo --quiet\n",
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/AI/ERA_course/session17"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oarNTHz1O3N",
        "outputId": "d4ce95c0-aa03-4197-a007-6b7bbd29e2c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/AI/ERA_course/session17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import transformer\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "IeoEvhBx1sPJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations = 20\n",
        "batch_size   = 16\n",
        "seq_len      = 64 # also known as blocks in gpt\n",
        "eval_iteration = 5\n",
        "total_iterations_for_evaluation = 10\n",
        "device       = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "kENuh75FCePv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Load data and tokenize"
      ],
      "metadata": {
        "id": "yYV-93gK1U9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pth = 'english_data/english.txt'\n",
        "data_raw = open(data_pth, encoding =\"utf-8\").read()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "vocab_size = tokenizer.vocab_size\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3Ac6OKW1RDP",
        "outputId": "c093353d-2cc7-4915-aec8-2ea7699b1f46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(data_raw)\n",
        "token_indices = tokenizer.convert_tokens_to_ids(tokens)\n",
        "data_tokens = torch.tensor(token_indices, dtype = torch.long)\n",
        "len(data_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHIua5KR15FE",
        "outputId": "fd67b8c0-1fd0-4267-d645-738c1d17b7a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (37443 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37443"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdSVJ3-2E5F9",
        "outputId": "a6a777b3-40b1-49e6-87cd-73909d23a9de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5219,  1014,  1011,  ..., 12375,  2015,  1012])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9 * len(data_tokens))\n",
        "train_data = data_tokens[:n]\n",
        "val_data = data_tokens[n:]"
      ],
      "metadata": {
        "id": "COLjGrCP3GY5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Load Model"
      ],
      "metadata": {
        "id": "_QYBqCRP3zae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_gpt = transformer.Gpt(n_embeddings = vocab_size)\n",
        "my_gpt.to(device)\n",
        "optimizer = torch.optim.Adam(params = my_gpt.parameters())\n",
        "summary(model= my_gpt, input_size=(32,64), dtypes = [torch.int32],col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT8rL7NK31RC",
        "outputId": "86bb9f69-f21d-4d61-c780-d3fe8f28c22a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "Gpt (Gpt)                                                    [32, 64]             [32, 64, 30522]      49,152               True\n",
              "├─Embedding (embeddings)                                     [32, 64]             [32, 64, 768]        23,440,896           True\n",
              "├─Dropout (embedding_dropout)                                [32, 64, 768]        [32, 64, 768]        --                   --\n",
              "├─Sequential (transformer_decoder)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    └─TransformerDecoderBlock (0)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock_Decoder (msa_block)      [32, 64, 768]        [32, 64, 768]        2,360,064            True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 64, 768]        [32, 64, 768]        789,248              True\n",
              "│    └─TransformerDecoderBlock (1)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock_Decoder (msa_block)      [32, 64, 768]        [32, 64, 768]        2,360,064            True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 64, 768]        [32, 64, 768]        789,248              True\n",
              "│    └─TransformerDecoderBlock (2)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock_Decoder (msa_block)      [32, 64, 768]        [32, 64, 768]        2,360,064            True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 64, 768]        [32, 64, 768]        789,248              True\n",
              "│    └─TransformerDecoderBlock (3)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock_Decoder (msa_block)      [32, 64, 768]        [32, 64, 768]        2,360,064            True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 64, 768]        [32, 64, 768]        789,248              True\n",
              "│    └─TransformerDecoderBlock (4)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock_Decoder (msa_block)      [32, 64, 768]        [32, 64, 768]        2,360,064            True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 64, 768]        [32, 64, 768]        789,248              True\n",
              "│    └─TransformerDecoderBlock (5)                           [32, 64, 768]        [32, 64, 768]        --                   True\n",
              "│    │    └─MultiHeadAttentionBlock_Decoder (msa_block)      [32, 64, 768]        [32, 64, 768]        2,360,064            True\n",
              "│    │    └─MLPBlock (mlp_block)                             [32, 64, 768]        [32, 64, 768]        789,248              True\n",
              "├─Sequential (output_logits)                                 [32, 64, 768]        [32, 64, 30522]      --                   True\n",
              "│    └─LayerNorm (0)                                         [32, 64, 768]        [32, 64, 768]        1,536                True\n",
              "│    └─Linear (1)                                            [32, 64, 768]        [32, 64, 30522]      23,440,896           True\n",
              "============================================================================================================================================\n",
              "Total params: 65,828,352\n",
              "Trainable params: 65,828,352\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 2.10\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 1028.55\n",
              "Params size (MB): 263.12\n",
              "Estimated Total Size (MB): 1291.68\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Train Model"
      ],
      "metadata": {
        "id": "F4DcVhkwCTCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data: list[str],seq_len:int, batch_size: int):\n",
        "  ix = torch.randint(len(data) - seq_len, (batch_size,))\n",
        "  x = torch.stack([data[i: i + seq_len] for i in ix])\n",
        "  y = torch.stack([data[i+1 : i + seq_len + 1] for i in ix])\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "xsa9GcP_BqRT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for it in tqdm(range(n_iterations)):\n",
        "  my_gpt.train()\n",
        "  x,y = get_batch(data = train_data,seq_len = seq_len, batch_size = batch_size)\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  logits,loss   = my_gpt(x,y)\n",
        "  train_loss += loss.item()\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # evaluation\n",
        "  if it % eval_iteration == 0:\n",
        "      print(\"Evaluating the model\")\n",
        "      my_gpt.eval()\n",
        "      losses = torch.zeros(total_iterations_for_evaluation)\n",
        "      for k in range(total_iterations_for_evaluation):\n",
        "          x,y = get_batch(data=val_data, seq_len = seq_len, batch_size=batch_size)\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          logits, loss = my_gpt(x, y)\n",
        "          losses[k] = loss.item()\n",
        "      val_loss = losses.mean()\n",
        "\n",
        "      losses = torch.zeros(total_iterations_for_evaluation)\n",
        "      for k in range(total_iterations_for_evaluation):\n",
        "          x,y = get_batch(data=train_data, seq_len = seq_len, batch_size=batch_size)\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          logits, loss = my_gpt(x, y)\n",
        "          losses[k] = loss.item()\n",
        "      train_loss = losses.mean()\n",
        "      print(\"step {:10} | train loss {:6.4f} | val loss {:6.4f}\".format(it, train_loss, val_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "8fef04649033473cb48c57b8cb39cb6c",
            "3e31c537ca534875a5a44111e6df6709",
            "21371f1313ed4b23ba67f400df4440cf",
            "02048bdae5fa4ec58bf95226b6f76b9e",
            "27639e3bd9fb489caa4a251998658e6a",
            "10ab641bd496414ca70ddd5275bb48e6",
            "3b01f022e5774501b247fc06346fe2a6",
            "f0e5fe7c141b4ccdb78b95c932fddacc",
            "7659d76c8180441290bd41d7b8987550",
            "0b0ba54573f44616a150b1f97d8d758f",
            "ec6e296628c3476ea9c85b09c8579f60"
          ]
        },
        "id": "afXZQXoGCaYc",
        "outputId": "3d66aab7-f801-40ab-8796-68951e72bff7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fef04649033473cb48c57b8cb39cb6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model\n",
            "step          0 | train loss 9.4621 | val loss 9.4609\n",
            "Evaluating the model\n",
            "step          5 | train loss 7.0127 | val loss 7.2627\n",
            "Evaluating the model\n",
            "step         10 | train loss 6.8966 | val loss 7.3043\n",
            "Evaluating the model\n",
            "step         15 | train loss 6.7066 | val loss 7.1931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My notes:\n",
        "B = 16\n",
        "T = 64\n",
        "\n",
        "input batch (16,64)\n",
        "\n",
        "token embeddings (16,64,768)\n",
        "\n",
        "position embeddings (64, 768)"
      ],
      "metadata": {
        "id": "YpjyV18Cj2zd"
      }
    }
  ]
}