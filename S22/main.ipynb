{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8V5THS_-wLAS","outputId":"2d3da074-d648-4443-9823-7f5e574c77fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install lightning --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieLqAKgOwLAW","outputId":"3dac50e3-9cd8-4aed-cac2-2047910fcaf6"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ug-8mXoYwLAX"},"outputs":[],"source":["import glob\n","import math\n","import sys\n","import time\n","from pathlib import Path\n","from typing import Optional, Tuple, Union\n","\n","import lightning as L\n","import torch\n","from lightning.fabric.loggers import CSVLogger\n","from lightning.fabric.strategies import FSDPStrategy\n","from torch.utils.data import DataLoader\n","\n","# # support running without installing as a package\n","# wd = Path(__file__).parent.parent.resolve()\n","# sys.path.append(str(wd))\n","\n","from tsai_gpt.model import GPT, Block, Config\n","from tsai_gpt.packed_dataset import CombinedDataset, PackedDataset\n","from tsai_gpt.speed_monitor import SpeedMonitorBase, estimate_flops, measure_flops\n","from tsai_gpt.speed_monitor import SpeedMonitorFabric as SpeedMonitor\n","from tsai_gpt.utils import chunked_cross_entropy, get_default_supported_precision, num_parameters, load_checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0a9JkMy2wLAY"},"outputs":[],"source":["model_name = \"pythia-160m\"\n","name = \"redpajama\"\n","out_dir = Path(\"out\") / name\n","save_interval = 1000\n","eval_interval = 1000\n","eval_iters = 100\n","log_interval = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wqwLPIAwLAZ"},"outputs":[],"source":["# Hyperparameters\n","learning_rate = 6e-3\n","batch_size = 32\n","micro_batch_size = 8\n","gradient_accumulation_steps = batch_size // micro_batch_size\n","assert gradient_accumulation_steps > 0\n","#max_iters = 600000  # num_epochs * (epoch_size // micro_batch_size) // devices\n","max_iters = 15000\n","weight_decay = 1e-1\n","beta1 = 0.9\n","beta2 = 0.95\n","grad_clip = 1.0\n","decay_lr = True\n","warmup_iters = 2000\n","lr_decay_iters = max_iters\n","min_lr = 6e-6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NT0PIEyXwLAZ"},"outputs":[],"source":["# Data proportions from https://arxiv.org/pdf/2302.13971.pdf Table 1\n","data_config = [\n","    (\"arxiv\", 5.0),\n","    (\"book\", 20.0),\n","    (\"c4\", 15.0),\n","    (\"cc\", 55.0),\n","    (\"github\", 4.5),\n","    (\"stackexchange\", 2.0),\n","    (\"wikipedia\", 5.0),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQAEcCyqwLAa"},"outputs":[],"source":["hparams = {k: v for k, v in locals().items() if isinstance(v, (int, float, str)) and not k.startswith(\"_\")}\n","logger = CSVLogger(\"out\", name, flush_logs_every_n_steps=log_interval)\n","\n","\n","def setup(\n","    devices: int = 4,\n","    train_data_dir: Path = Path(\"data/redpajama_sample\"),\n","    val_data_dir: Optional[Path] = None,\n","    precision: Optional[str] = None,\n","    resume: Union[bool, Path] = False,\n",") -> None:\n","    precision = precision or get_default_supported_precision(training=True)\n","\n","    if devices > 1:\n","        strategy = FSDPStrategy(\n","            auto_wrap_policy={Block},\n","            activation_checkpointing_policy={Block},\n","            state_dict_type=\"full\",\n","            limit_all_gathers=True,\n","            cpu_offload=False,\n","        )\n","    else:\n","        strategy = \"auto\"\n","\n","    fabric = L.Fabric(devices=devices, strategy=strategy, precision=precision, loggers=logger)\n","    fabric.print(hparams)\n","    fabric.launch(main, train_data_dir, val_data_dir, resume)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"el7y4NAbwLAa"},"outputs":[],"source":["model_copy = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1mkcioywLAa"},"outputs":[],"source":["def main(fabric: L.Fabric, train_data_dir: Path, val_data_dir: Path, resume: Union[bool, Path]) -> None:\n","    global model_copy\n","    speed_monitor = SpeedMonitor(fabric, window_size=50, time_unit=\"seconds\")\n","\n","    if fabric.global_rank == 0:\n","        out_dir.mkdir(parents=True, exist_ok=True)\n","\n","    config = Config.from_name(model_name)\n","\n","    train_dataloader, val_dataloader = create_dataloaders(\n","        batch_size=micro_batch_size,\n","        block_size=config.block_size,\n","        fabric=fabric,\n","        train_data_dir=train_data_dir,\n","        val_data_dir=val_data_dir,\n","        seed=(1337 + fabric.global_rank),\n","    )\n","    if val_dataloader is None:\n","        train_dataloader = fabric.setup_dataloaders(train_dataloader)\n","    else:\n","        train_dataloader, val_dataloader = fabric.setup_dataloaders(train_dataloader, val_dataloader)\n","\n","    fabric.seed_everything(1337)  # same seed for every process to init model (FSDP)\n","\n","    fabric.print(f\"Loading model with {config.__dict__}\")\n","    t0 = time.perf_counter()\n","    import torch\n","    import torch.nn as nn\n","    def _init_weights(module: nn.Module) -> None:\n","            \"\"\"Meant to be used with `gpt.apply(gpt._init_weights)`.\"\"\"\n","            if isinstance(module, nn.Linear):\n","                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","                if module.bias is not None:\n","                    torch.nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.Embedding):\n","                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    with fabric.init_module(empty_init=True):\n","        model = GPT(config)\n","        model.apply(_init_weights)\n","    model.apply(_init_weights)\n","\n","\n","    # checkpoint_path = Path(\"out/redpajama/iter-000999-ckpt.pth\")\n","\n","    # load_checkpoint(fabric, model, checkpoint_path)\n","\n","    # print(model.transformer.h[0].mlp.fc.weight)\n","\n","    fabric.print(f\"Time to instantiate model: {time.perf_counter() - t0:.02f} seconds.\")\n","    fabric.print(f\"Total parameters {num_parameters(model):,}\")\n","\n","    model = fabric.setup(model)\n","    optimizer = torch.optim.AdamW(\n","        model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=(beta1, beta2), foreach=False\n","    )\n","\n","    # model_copy = model\n","\n","    optimizer = fabric.setup_optimizers(optimizer)\n","\n","    state = {\"model\": model, \"optimizer\": optimizer, \"hparams\": hparams, \"iter_num\": 0, \"step_count\": 0}\n","\n","    if resume is True:\n","        resume = max(out_dir.glob(\"*.pth\"), key=lambda p: int(p.name.split(\"-\")[1]))\n","    if resume:\n","        fabric.print(f\"Resuming training from {resume}\")\n","        fabric.load(resume, state)\n","\n","    train_time = time.perf_counter()\n","    train(fabric, state, train_dataloader, val_dataloader, speed_monitor)\n","    fabric.print(f\"Training time: {(time.perf_counter()-train_time):.2f}s\")\n","    if fabric.device.type == \"cuda\":\n","        fabric.print(f\"Memory used: {torch.cuda.max_memory_allocated() / 1e9:.02f} GB\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FL9C0xjXwLAb"},"outputs":[],"source":["def train(\n","    fabric: L.Fabric,\n","    state: dict,\n","    train_dataloader: DataLoader,\n","    val_dataloader: DataLoader,\n","    speed_monitor: SpeedMonitorBase,\n",") -> None:\n","    model = state[\"model\"]\n","    optimizer = state[\"optimizer\"]\n","\n","    if val_dataloader is not None:\n","        validate(fabric, model, val_dataloader)  # sanity check\n","\n","    with torch.device(\"meta\"):\n","        meta_model = GPT(model.config)\n","        # \"estimated\" is not as precise as \"measured\". Estimated is optimistic but widely used in the wild.\n","        # When comparing MFU or FLOP numbers with other projects that use estimated FLOPs,\n","        # consider passing `SpeedMonitor(flops_per_batch=estimated_flops)` instead\n","        estimated_flops = estimate_flops(meta_model) * micro_batch_size\n","        fabric.print(f\"Estimated TFLOPs: {estimated_flops * fabric.world_size / 1e12:.2f}\")\n","        x = torch.randint(0, 1, (micro_batch_size, model.max_seq_length))\n","        measured_flops = measure_flops(meta_model, x)\n","        fabric.print(f\"Measured TFLOPs: {measured_flops * fabric.world_size / 1e12:.2f}\")\n","        del meta_model, x\n","\n","    total_lengths = 0\n","    total_t0 = time.perf_counter()\n","\n","    for state[\"iter_num\"], train_data in enumerate(train_dataloader, state[\"iter_num\"]):\n","        if state[\"iter_num\"] >= max_iters:\n","            checkpoint_path = out_dir / f\"iter-{state['iter_num']:06d}-ckpt.pth\"\n","            fabric.print(f\"Saving checkpoint to {str(checkpoint_path)!r}\")\n","            fabric.save(checkpoint_path, state)\n","            break\n","\n","        # determine and set the learning rate for this iteration\n","        lr = get_lr(state[\"iter_num\"]) if decay_lr else learning_rate\n","        for param_group in optimizer.param_groups:\n","            param_group[\"lr\"] = lr\n","\n","        iter_t0 = time.perf_counter()\n","\n","        input_ids = train_data[:, 0 : model.max_seq_length].contiguous()\n","        targets = train_data[:, 1 : model.max_seq_length + 1].contiguous()\n","\n","        is_accumulating = (state[\"iter_num\"] + 1) % gradient_accumulation_steps != 0\n","        with fabric.no_backward_sync(model, enabled=is_accumulating):\n","            logits = model(input_ids)\n","            loss = chunked_cross_entropy(logits, targets, chunk_size=0)\n","            fabric.backward(loss / gradient_accumulation_steps)\n","\n","        # return\n","\n","        if not is_accumulating:\n","            fabric.clip_gradients(model, optimizer, max_norm=grad_clip)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            state[\"step_count\"] += 1\n","\n","        t1 = time.perf_counter()\n","        total_lengths += input_ids.size(1)\n","        speed_monitor.on_train_batch_end(\n","            (state[\"iter_num\"] + 1) * micro_batch_size,\n","            t1 - total_t0,\n","            # this assumes that device FLOPs are the same and that all devices have the same batch size\n","            fabric.world_size,\n","            flops_per_batch=measured_flops,\n","            lengths=total_lengths,\n","        )\n","        if state[\"iter_num\"] % log_interval == 0:\n","            fabric.print(\n","                f\"iter {state['iter_num']} step {state['step_count']}: loss {loss.item():.4f}, LR: {lr:.6f}, iter time:\"\n","                f\" {(t1 - iter_t0) * 1000:.2f}ms{' (optimizer.step)' if not is_accumulating else ''}\"\n","            )\n","\n","        if val_dataloader is not None and not is_accumulating and state[\"step_count\"] % eval_interval == 0:\n","            t0 = time.perf_counter()\n","            val_loss = validate(fabric, model, val_dataloader)\n","            t1 = time.perf_counter() - t0\n","            speed_monitor.eval_end(t1)\n","            fabric.print(f\"step {state['iter_num']}: val loss {val_loss.item():.4f}, val time: {t1 * 1000:.2f}ms\")\n","            fabric.barrier()\n","        if not is_accumulating and state[\"step_count\"] % save_interval == 0:\n","            checkpoint_path = out_dir / f\"iter-{state['iter_num']:06d}-ckpt.pth\"\n","            fabric.print(f\"Saving checkpoint to {str(checkpoint_path)!r}\")\n","            fabric.save(checkpoint_path, state)\n","\n","    checkpoint_path = out_dir / f\"iter-{state['iter_num']:06d}-ckpt.pth\"\n","    fabric.print(f\"Saving checkpoint to {str(checkpoint_path)!r}\")\n","    fabric.save(checkpoint_path, state)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRkhOTHbwLAc"},"outputs":[],"source":["@torch.inference_mode()\n","def validate(fabric: L.Fabric, model: torch.nn.Module, val_dataloader: DataLoader) -> torch.Tensor:\n","    fabric.print(\"Validating ...\")\n","    model.eval()\n","\n","    losses = torch.zeros(eval_iters, device=fabric.device)\n","    for k, val_data in enumerate(val_dataloader):\n","        input_ids = val_data[:, 0 : model.max_seq_length].contiguous()\n","        targets = val_data[:, 1 : model.max_seq_length + 1].contiguous()\n","        logits = model(input_ids)\n","        losses[k] = chunked_cross_entropy(logits, targets, chunk_size=0)\n","    out = losses.mean()\n","\n","    model.train()\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZJJzHfuwLAc"},"outputs":[],"source":["def create_dataloader(\n","    batch_size: int, block_size: int, data_dir: Path, fabric: L.Fabric, shuffle: bool = True, seed: int = 12345\n",") -> DataLoader:\n","    datasets = []\n","    for prefix, _ in data_config:\n","        filenames = glob.glob(str(data_dir / f\"{prefix}*\"))\n","        dataset = PackedDataset(\n","            filenames,\n","            n_chunks=4,\n","            block_size=block_size,\n","            shuffle=shuffle,\n","            seed=seed,\n","            num_processes=fabric.world_size,\n","            process_rank=fabric.global_rank,\n","        )\n","        datasets.append(dataset)\n","\n","    if not datasets:\n","        raise RuntimeError(\n","            f\"No data found at {data_dir}. Make sure you ran prepare_redpajama.py to create the dataset.\"\n","        )\n","\n","    weights = [weight for _, weight in data_config]\n","    sum_weights = sum(weights)\n","    weights = [el / sum_weights for el in weights]\n","\n","    combined_dataset = CombinedDataset(datasets=datasets, seed=seed, weights=weights)\n","\n","    return DataLoader(combined_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KfNj41kwLAc"},"outputs":[],"source":["def create_dataloaders(\n","    batch_size: int,\n","    block_size: int,\n","    fabric: L.Fabric,\n","    train_data_dir: Path = Path(\"data/redpajama_sample\"),\n","    val_data_dir: Optional[Path] = None,\n","    seed: int = 12345,\n",") -> Tuple[DataLoader, DataLoader]:\n","    # Increase by one because we need the next word as well\n","    effective_block_size = block_size + 1\n","    train_dataloader = create_dataloader(\n","        batch_size=batch_size,\n","        block_size=effective_block_size,\n","        fabric=fabric,\n","        data_dir=train_data_dir,\n","        shuffle=True,\n","        seed=seed,\n","    )\n","    val_dataloader = (\n","        create_dataloader(\n","            batch_size=batch_size,\n","            block_size=effective_block_size,\n","            fabric=fabric,\n","            data_dir=val_data_dir,\n","            shuffle=False,\n","            seed=seed,\n","        )\n","        if val_data_dir\n","        else None\n","    )\n","    return train_dataloader, val_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYvp4bjUwLAc"},"outputs":[],"source":["def get_lr(it: int) -> float:\n","    # 1) linear warmup for warmup_iters steps\n","    if it < warmup_iters:\n","        return learning_rate * it / warmup_iters\n","    # 2) if it > lr_decay_iters, return min learning rate\n","    if it > lr_decay_iters:\n","        return min_lr\n","    # 3) in between, use cosine decay down to min learning rate\n","    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n","    assert 0 <= decay_ratio <= 1\n","    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n","    return min_lr + coeff * (learning_rate - min_lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNctm2yrwLAd","outputId":"c139d9da-2fb5-4d83-ba82-f3e6b881a892"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using bfloat16 Automatic Mixed Precision (AMP)\n","Seed set to 1337\n"]},{"name":"stdout","output_type":"stream","text":["{'model_name': 'pythia-160m', 'name': 'redpajama', 'save_interval': 1000, 'eval_interval': 1000, 'eval_iters': 100, 'log_interval': 100, 'learning_rate': 0.006, 'batch_size': 32, 'micro_batch_size': 8, 'gradient_accumulation_steps': 4, 'max_iters': 15000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 15000, 'min_lr': 6e-06}\n","Loading model with {'name': 'pythia-160m', 'hf_config': {'org': 'EleutherAI', 'name': 'pythia-160m-deduped'}, 'block_size': 2048, 'vocab_size': 50254, 'padding_multiple': 128, 'padded_vocab_size': 50304, 'n_layer': 12, 'n_head': 12, 'n_embd': 768, 'rotary_percentage': 0.25, 'parallel_residual': True, 'bias': True, 'lm_head_bias': False, 'n_query_groups': 12, 'shared_attention_norm': False, '_norm_class': 'LayerNorm', 'norm_eps': 1e-05, '_mlp_class': 'GptNeoxMLP', 'gelu_approximate': 'none', 'intermediate_size': 3072, 'rope_condense_ratio': 1, 'rope_base': 10000, 'head_size': 64, 'rope_n_elem': 16}\n","Time to instantiate model: 0.28 seconds.\n","Total parameters 162,322,944\n","Estimated TFLOPs: 22.14\n","Measured TFLOPs: 15.86\n","iter 0 step 0: loss 11.0059, LR: 0.000000, iter time: 662.28ms\n","iter 100 step 25: loss 7.5064, LR: 0.000300, iter time: 38.55ms\n","iter 200 step 50: loss 6.8100, LR: 0.000600, iter time: 39.23ms\n","iter 300 step 75: loss 6.1853, LR: 0.000900, iter time: 39.39ms\n","iter 400 step 100: loss 6.0197, LR: 0.001200, iter time: 40.02ms\n","iter 500 step 125: loss 5.8854, LR: 0.001500, iter time: 43.52ms\n","iter 600 step 150: loss 5.5158, LR: 0.001800, iter time: 80.45ms\n","iter 700 step 175: loss 5.7466, LR: 0.002100, iter time: 117.69ms\n","iter 800 step 200: loss 5.4462, LR: 0.002400, iter time: 119.30ms\n","iter 900 step 225: loss 5.3457, LR: 0.002700, iter time: 115.15ms\n","iter 1000 step 250: loss 5.3444, LR: 0.003000, iter time: 116.98ms\n","iter 1100 step 275: loss 5.1460, LR: 0.003300, iter time: 118.31ms\n","iter 1200 step 300: loss 5.3354, LR: 0.003600, iter time: 126.11ms\n","iter 1300 step 325: loss 5.1215, LR: 0.003900, iter time: 123.33ms\n","iter 1400 step 350: loss 5.3447, LR: 0.004200, iter time: 118.56ms\n","iter 1500 step 375: loss 5.1897, LR: 0.004500, iter time: 124.27ms\n","iter 1600 step 400: loss 5.2543, LR: 0.004800, iter time: 123.56ms\n","iter 1700 step 425: loss 4.7917, LR: 0.005100, iter time: 124.70ms\n","iter 1800 step 450: loss 4.7591, LR: 0.005400, iter time: 123.93ms\n","iter 1900 step 475: loss 5.0317, LR: 0.005700, iter time: 125.00ms\n","iter 2000 step 500: loss 4.7684, LR: 0.006000, iter time: 124.17ms\n","iter 2100 step 525: loss 4.6804, LR: 0.005999, iter time: 124.18ms\n","iter 2200 step 550: loss 5.1235, LR: 0.005997, iter time: 124.49ms\n","iter 2300 step 575: loss 4.7008, LR: 0.005992, iter time: 120.61ms\n","iter 2400 step 600: loss 4.7170, LR: 0.005986, iter time: 96.21ms\n","iter 2500 step 625: loss 4.5571, LR: 0.005978, iter time: 125.97ms\n","iter 2600 step 650: loss 4.6210, LR: 0.005969, iter time: 125.82ms\n","iter 2700 step 675: loss 4.5113, LR: 0.005957, iter time: 118.65ms\n","iter 2800 step 700: loss 4.5060, LR: 0.005944, iter time: 119.83ms\n","iter 2900 step 725: loss 4.3081, LR: 0.005929, iter time: 124.91ms\n","iter 3000 step 750: loss 4.1304, LR: 0.005913, iter time: 123.00ms\n","iter 3100 step 775: loss 4.5153, LR: 0.005895, iter time: 125.11ms\n","iter 3200 step 800: loss 4.4473, LR: 0.005875, iter time: 118.63ms\n","iter 3300 step 825: loss 4.4590, LR: 0.005853, iter time: 123.41ms\n","iter 3400 step 850: loss 4.4132, LR: 0.005830, iter time: 125.91ms\n","iter 3500 step 875: loss 4.0853, LR: 0.005805, iter time: 125.76ms\n","iter 3600 step 900: loss 4.1677, LR: 0.005779, iter time: 118.46ms\n","iter 3700 step 925: loss 4.0198, LR: 0.005751, iter time: 124.16ms\n","iter 3800 step 950: loss 4.2300, LR: 0.005721, iter time: 123.48ms\n","iter 3900 step 975: loss 4.2335, LR: 0.005690, iter time: 117.53ms\n","Saving checkpoint to 'out/redpajama/iter-003999-ckpt.pth'\n","iter 4000 step 1000: loss 4.1256, LR: 0.005657, iter time: 60.60ms\n","iter 4100 step 1025: loss 3.7622, LR: 0.005622, iter time: 125.73ms\n","iter 4200 step 1050: loss 4.1543, LR: 0.005586, iter time: 125.24ms\n","iter 4300 step 1075: loss 4.2406, LR: 0.005549, iter time: 124.26ms\n","iter 4400 step 1100: loss 3.7797, LR: 0.005510, iter time: 124.28ms\n","iter 4500 step 1125: loss 4.2093, LR: 0.005469, iter time: 118.87ms\n","iter 4600 step 1150: loss 3.8776, LR: 0.005428, iter time: 123.40ms\n","iter 4700 step 1175: loss 3.4995, LR: 0.005384, iter time: 100.39ms\n","iter 4800 step 1200: loss 4.1353, LR: 0.005340, iter time: 136.25ms\n","iter 4900 step 1225: loss 4.0262, LR: 0.005294, iter time: 122.29ms\n","iter 5000 step 1250: loss 4.2450, LR: 0.005246, iter time: 121.85ms\n","iter 5100 step 1275: loss 4.0047, LR: 0.005198, iter time: 100.05ms\n","iter 5200 step 1300: loss 3.9196, LR: 0.005148, iter time: 124.58ms\n","iter 5300 step 1325: loss 4.0657, LR: 0.005096, iter time: 125.37ms\n","iter 5400 step 1350: loss 4.3711, LR: 0.005044, iter time: 124.49ms\n","iter 5500 step 1375: loss 3.6200, LR: 0.004990, iter time: 121.28ms\n","iter 5600 step 1400: loss 2.9517, LR: 0.004936, iter time: 121.71ms\n","iter 5700 step 1425: loss 3.6120, LR: 0.004880, iter time: 105.32ms\n","iter 5800 step 1450: loss 3.4006, LR: 0.004823, iter time: 117.80ms\n","iter 5900 step 1475: loss 3.5683, LR: 0.004765, iter time: 117.35ms\n","iter 6000 step 1500: loss 4.0087, LR: 0.004705, iter time: 156.95ms\n","iter 6100 step 1525: loss 3.5602, LR: 0.004645, iter time: 123.89ms\n","iter 6200 step 1550: loss 4.1096, LR: 0.004584, iter time: 116.70ms\n","iter 6300 step 1575: loss 3.8554, LR: 0.004522, iter time: 121.75ms\n","iter 6400 step 1600: loss 3.4208, LR: 0.004459, iter time: 109.91ms\n","iter 6500 step 1625: loss 3.6404, LR: 0.004396, iter time: 123.55ms\n","iter 6600 step 1650: loss 3.7165, LR: 0.004331, iter time: 121.79ms\n","iter 6700 step 1675: loss 3.5329, LR: 0.004266, iter time: 116.64ms\n","iter 6800 step 1700: loss 4.0225, LR: 0.004200, iter time: 121.97ms\n","iter 6900 step 1725: loss 3.5632, LR: 0.004133, iter time: 118.54ms\n","iter 7000 step 1750: loss 3.9018, LR: 0.004066, iter time: 123.09ms\n","iter 7100 step 1775: loss 3.4298, LR: 0.003998, iter time: 96.57ms\n","iter 7200 step 1800: loss 3.0097, LR: 0.003929, iter time: 118.05ms\n","iter 7300 step 1825: loss 3.8296, LR: 0.003860, iter time: 118.69ms\n","iter 7400 step 1850: loss 3.6514, LR: 0.003790, iter time: 116.95ms\n","iter 7500 step 1875: loss 3.5058, LR: 0.003720, iter time: 117.79ms\n","iter 7600 step 1900: loss 3.3857, LR: 0.003650, iter time: 118.20ms\n","iter 7700 step 1925: loss 3.4840, LR: 0.003579, iter time: 120.88ms\n","iter 7800 step 1950: loss 3.6298, LR: 0.003508, iter time: 114.50ms\n","iter 7900 step 1975: loss 3.6116, LR: 0.003436, iter time: 105.46ms\n","Saving checkpoint to 'out/redpajama/iter-007999-ckpt.pth'\n","iter 8000 step 2000: loss 3.9115, LR: 0.003364, iter time: 60.59ms\n","iter 8100 step 2025: loss 3.7595, LR: 0.003292, iter time: 116.47ms\n","iter 8200 step 2050: loss 2.7943, LR: 0.003220, iter time: 115.56ms\n","iter 8300 step 2075: loss 3.7653, LR: 0.003148, iter time: 118.52ms\n","iter 8400 step 2100: loss 3.5017, LR: 0.003075, iter time: 116.03ms\n","iter 8500 step 2125: loss 3.8120, LR: 0.003003, iter time: 117.58ms\n","iter 8600 step 2150: loss 3.1426, LR: 0.002931, iter time: 122.42ms\n","iter 8700 step 2175: loss 3.5352, LR: 0.002858, iter time: 121.50ms\n","iter 8800 step 2200: loss 2.7297, LR: 0.002786, iter time: 116.84ms\n","iter 8900 step 2225: loss 3.5426, LR: 0.002714, iter time: 125.08ms\n","iter 9000 step 2250: loss 3.4227, LR: 0.002642, iter time: 111.52ms\n","iter 9100 step 2275: loss 3.7351, LR: 0.002570, iter time: 124.87ms\n","iter 9200 step 2300: loss 3.8121, LR: 0.002498, iter time: 125.34ms\n","iter 9300 step 2325: loss 3.5310, LR: 0.002427, iter time: 126.53ms\n","iter 9400 step 2350: loss 3.2172, LR: 0.002356, iter time: 119.21ms\n","iter 9500 step 2375: loss 3.4819, LR: 0.002286, iter time: 118.42ms\n","iter 9600 step 2400: loss 3.1216, LR: 0.002216, iter time: 118.32ms\n","iter 9700 step 2425: loss 3.8417, LR: 0.002146, iter time: 124.78ms\n","iter 9800 step 2450: loss 3.0850, LR: 0.002077, iter time: 122.07ms\n","iter 9900 step 2475: loss 3.5344, LR: 0.002008, iter time: 118.13ms\n","iter 10000 step 2500: loss 3.2343, LR: 0.001940, iter time: 114.49ms\n","iter 10100 step 2525: loss 3.8201, LR: 0.001873, iter time: 117.37ms\n","iter 10200 step 2550: loss 3.4535, LR: 0.001806, iter time: 115.10ms\n","iter 10300 step 2575: loss 3.6723, LR: 0.001740, iter time: 118.19ms\n","iter 10400 step 2600: loss 2.9395, LR: 0.001675, iter time: 93.06ms\n","iter 10500 step 2625: loss 3.7392, LR: 0.001610, iter time: 123.64ms\n","iter 10600 step 2650: loss 3.0708, LR: 0.001547, iter time: 117.00ms\n","iter 10700 step 2675: loss 3.2986, LR: 0.001484, iter time: 117.47ms\n","iter 10800 step 2700: loss 3.5939, LR: 0.001422, iter time: 89.77ms\n","iter 10900 step 2725: loss 3.4297, LR: 0.001361, iter time: 116.42ms\n","Saving checkpoint to 'out/redpajama/iter-010915-ckpt.pth'\n","Training time: 5066.80s\n","Memory used: 21.58 GB\n"]}],"source":["torch.set_float32_matmul_precision(\"medium\")\n","setup(\n","    devices=1,\n","    train_data_dir=Path(\"data/data/lit-redpajama-sample\")\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}