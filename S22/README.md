# Training GPT from scratch using arxiv + book + cc.

## Key Features:
  1. Parameter Count: 160M
  2. Pythia-160M
  3. Training Loss 3.4297.
  4. Embedding Dimension: 768.
  5. Context Length: 2048.

## Hugging Face Spaces Link:

https://huggingface.co/spaces/sanjanatule/GPTNext


## Generate Dialogue for a character using the trained model - examples


